{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVITPcKy0ccrP0FllhkicL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michel-p16/PDS-Project/blob/Michel/DataGeneration_PDS_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "qH1MaozfVopb",
        "outputId": "60ed387e-ec37-4e28-9a7e-bcd40498bd65"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-452040ba-1f45-4fa1-92d3-d80e8f3bec45\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-452040ba-1f45-4fa1-92d3-d80e8f3bec45\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving questionnaire1.json to questionnaire1.json\n",
            "Saving questionnaire2.json to questionnaire2.json\n",
            "Saving questionnaire3.json to questionnaire3.json\n",
            "Saving questionnaire4.json to questionnaire4.json\n",
            "Saving questionnaire5.json to questionnaire5.json\n",
            "Datei questionnaire1.json wurde hochgeladen.\n",
            "Datei questionnaire2.json wurde hochgeladen.\n",
            "Datei questionnaire3.json wurde hochgeladen.\n",
            "Datei questionnaire4.json wurde hochgeladen.\n",
            "Datei questionnaire5.json wurde hochgeladen.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Datei hochladen\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Zeigt die hochgeladene Datei an\n",
        "for file_name in uploaded.keys():\n",
        "    print(f\"Datei {file_name} wurde hochgeladen.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "file_names = [\n",
        "    \"questionnaire1.json\",\n",
        "    \"questionnaire2.json\",\n",
        "    \"questionnaire3.json\",\n",
        "    \"questionnaire4.json\",\n",
        "    \"questionnaire5.json\"\n",
        "]\n",
        "\n",
        "data_list = []\n",
        "\n",
        "# Jede Datei einzeln lesen\n",
        "for file_name in file_names:\n",
        "    with open(file_name, 'r') as f:\n",
        "        data = json.load(f)\n",
        "        data_list.append(data)\n",
        "\n",
        "# Daten für jede Datei anzeigen\n",
        "for i, data in enumerate(data_list):\n",
        "    print(f\"Datei {file_names[i]} enthält {len(data)} Fragen.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2_gcWf2gFyz",
        "outputId": "c3f10fa6-e49f-48fa-840b-94b633b7b41c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datei questionnaire1.json enthält 5 Fragen.\n",
            "Datei questionnaire2.json enthält 4 Fragen.\n",
            "Datei questionnaire3.json enthält 4 Fragen.\n",
            "Datei questionnaire4.json enthält 5 Fragen.\n",
            "Datei questionnaire5.json enthält 7 Fragen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Beispiel: Alle Fragen aus allen Dateien ausgeben\n",
        "for file_data in data_list:\n",
        "    for question in file_data:\n",
        "        print(f\"Frage: {question['question']}, Typ: {question['type']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBvUOiPMgQth",
        "outputId": "84cdec21-6a24-4b31-d9b9-d1a14611c017"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frage: Data processing consent, Typ: SINGLE_SELECT\n",
            "Frage: Customer group, Typ: SINGLE_SELECT\n",
            "Frage: Products interested in, Typ: MULTI_SELECT\n",
            "Frage: What kind of follow up is planned, Typ: MULTI_SELECT\n",
            "Frage: Who to copy in follow up, Typ: MULTI_SELECT\n",
            "Frage: Would you like to receive marketing information from via e-mail?, Typ: SINGLE_SELECT\n",
            "Frage: What industry are you operating in?, Typ: SINGLE_SELECT\n",
            "Frage: What products are you interested in?, Typ: MULTI_SELECT\n",
            "Frage: Notes, Typ: TEXT\n",
            "Frage: What type of company is it?, Typ: SINGLE_SELECT\n",
            "Frage: What is the size of your company?, Typ: SINGLE_SELECT\n",
            "Frage: When do you wish to receive a follow-up?, Typ: DATE\n",
            "Frage: Any additional notes?, Typ: TEXT\n",
            "Frage: Which language is wanted for communication? , Typ: SINGLE_SELECT\n",
            "Frage: What is the type of contact?, Typ: MULTI_SELECT\n",
            "Frage: What is the contact person interested in?, Typ: MULTI_SELECT\n",
            "Frage: What phone number can we use for contact?, Typ: NUMBER\n",
            "Frage: When does the contact person wish to receive a follow up?, Typ: MULTI_SELECT\n",
            "Frage: Customer type, Typ: SINGLE_SELECT\n",
            "Frage: Customer satisfaction, Typ: SINGLE_SELECT\n",
            "Frage: Size of the trade fair team (on average), Typ: SINGLE_SELECT\n",
            "Frage: CRM-System, Typ: SINGLE_SELECT\n",
            "Frage: Productinterests, Typ: MULTI_SELECT\n",
            "Frage: Searches a solution for, Typ: MULTI_SELECT\n",
            "Frage: Next steps, Typ: SINGLE_SELECT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_questions = [q for file_data in data_list for q in file_data]\n",
        "print(f\"Insgesamt {len(combined_questions)} Fragen aus allen Dateien.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTlr4f9bgf5l",
        "outputId": "1eaa9084-ac81-4a68-eca3-d8f7fae4c776"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insgesamt 25 Fragen aus allen Dateien.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import time\n",
        "from google.colab import userdata\n",
        "\n",
        "# API-Schlüssel abrufen, der in Colab Secrets gespeichert wurde\n",
        "key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# API-Schlüssel konfigurieren, um die Gemini API zu nutzen\n",
        "if key:\n",
        "    genai.configure(api_key=key)\n",
        "else:\n",
        "    raise ValueError(\"API-Schlüssel konnte nicht abgerufen werden. Bitte sicherstellen, dass der Schlüssel in Colab Secrets gespeichert wurde.\")\n",
        "\n",
        "# Modell laden\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Funktion, um die Frage mit der Gemini API zu reformulieren\n",
        "def reformulate_question(question_text):\n",
        "    try:\n",
        "        prompt = f\"Rewrite the following text as a proper question to a customer: '{question_text}. Keep it short and natural'\"\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config={\n",
        "                \"temperature\": 0.7,\n",
        "                \"max_output_tokens\": 50\n",
        "            }\n",
        "        )\n",
        "        return response.text.strip() if response and response.text else question_text\n",
        "    except Exception as e:\n",
        "        print(f\"Fehler bei der Frageumformulierung: {e}\")\n",
        "        return question_text\n",
        "\n",
        "# Fragen aus `combined_questions` reformulieren\n",
        "for question in combined_questions:\n",
        "    original_question = question[\"question\"]\n",
        "    question[\"question\"] = reformulate_question(original_question)\n",
        "    print(f\"Original: {original_question}\\nReformuliert: {question['question']}\\n\")\n",
        "    time.sleep(5)  # Verzögerung von 5 Sekunden zwischen den Anfragen\n",
        "\n",
        "# Ergebnisse speichern\n",
        "output_file = 'reformulated_combined_questions.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(combined_questions, f, indent=4)\n",
        "\n",
        "print(f\"Reformulierte Fragen wurden in '{output_file}' gespeichert.\")\n",
        "\n",
        "# Datei herunterladen\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o_ST2bHolhKn",
        "outputId": "19b11ae0-db9a-4f43-931d-b8317d2c3f18"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: Data processing consent\n",
            "Reformuliert: May we process your data?\n",
            "\n",
            "Original: Customer group\n",
            "Reformuliert: What's your customer group?\n",
            "\n",
            "Original: Products interested in\n",
            "Reformuliert: Which products are you interested in?\n",
            "\n",
            "Original: What kind of follow up is planned\n",
            "Reformuliert: What's the follow-up plan?\n",
            "\n",
            "Original: Who to copy in follow up\n",
            "Reformuliert: Who should I CC on the follow-up?\n",
            "\n",
            "Original: Would you like to receive marketing information from via e-mail?\n",
            "Reformuliert: Want marketing emails?\n",
            "\n",
            "Original: What industry are you operating in?\n",
            "Reformuliert: What industry are you in?\n",
            "\n",
            "Original: What products are you interested in?\n",
            "Reformuliert: What are you interested in?\n",
            "\n",
            "Original: Notes\n",
            "Reformuliert: Could you please leave a short note?\n",
            "\n",
            "Original: What type of company is it?\n",
            "Reformuliert: What kind of company is this?\n",
            "\n",
            "Original: What is the size of your company?\n",
            "Reformuliert: How big is your company?\n",
            "\n",
            "Original: When do you wish to receive a follow-up?\n",
            "Reformuliert: When would you like a follow-up?\n",
            "\n",
            "Original: Any additional notes?\n",
            "Reformuliert: Anything else?\n",
            "\n",
            "Original: Which language is wanted for communication? \n",
            "Reformuliert: What language do you prefer?\n",
            "\n",
            "Original: What is the type of contact?\n",
            "Reformuliert: What type of contact is this?\n",
            "\n",
            "Original: What is the contact person interested in?\n",
            "Reformuliert: Who are you contacting us on behalf of?\n",
            "\n",
            "Original: What phone number can we use for contact?\n",
            "Reformuliert: What's your phone number?\n",
            "\n",
            "Original: When does the contact person wish to receive a follow up?\n",
            "Reformuliert: When would you like a follow-up?\n",
            "\n",
            "Original: Customer type\n",
            "Reformuliert: What type of customer are you?\n",
            "\n",
            "Original: Customer satisfaction\n",
            "Reformuliert: How satisfied were you with your experience?\n",
            "\n",
            "Original: Size of the trade fair team (on average)\n",
            "Reformuliert: How many people are typically on your trade fair team?\n",
            "\n",
            "Original: CRM-System\n",
            "Reformuliert: Are you interested in a CRM system?\n",
            "\n",
            "Original: Productinterests\n",
            "Reformuliert: What are your interests in our products?\n",
            "\n",
            "Original: Searches a solution for\n",
            "Reformuliert: What are you looking for?\n",
            "\n",
            "Original: Next steps\n",
            "Reformuliert: What's next?\n",
            "\n",
            "Reformulierte Fragen wurden in 'reformulated_combined_questions.json' gespeichert.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a8067ae8-5d7c-4430-b2e7-2c8d6832bff8\", \"reformulated_combined_questions.json\", 20031)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of prompts\n",
        "\n",
        "prompt_templates = {\n",
        "    \"SINGLE_SELECT\": [\n",
        "        \"Imagine you are a user. Respond to the question '{question_text}' by choosing the option '{option}'. Provide only the response, and do not include any explanations or examples. Be concise and realistic. Use about 7 words\",\n",
        "        \"Based on the option '{option}', how would a typical user answer the question: '{question_text}'?. Provide only the response, and do not include any explanations or examples. Use around 20 words for the answer\",\n",
        "        \"As a user, give a clear and concise answer to the question: '{question_text}' while including the option '{option}'. Provide only the response, and do not include any explanations or examples. use about 5 words\",\n",
        "        \"Respond conversationally to the question: '{question_text}', incorporating the choice '{option}'. Provide only the response, and do not include any explanations or examples.\",\n",
        "        \"What would a user realistically say to this question: '{question_text}', if they chose '{option}'? Provide only the response, and do not include any explanations or examples. Use around 20 words for the answer\"\n",
        "    ],\n",
        "\n",
        "    \"MULTI_SELECT\": [\n",
        "        \"If a user selects the options '{options}', how would they naturally respond to the question: '{question_text}'? Only provide the answer and nothing else. Use about 20 Words\",\n",
        "        \"Imagine a user answering the question: '{question_text}' based on the selected options '{options}'. Keep it realistic and concise. Only provide the answer and nothing else. Use about 10-15 words\",\n",
        "        \"What would a typical user say to the question: '{question_text}', considering their choices '{options}'? Make it sound conversational. Use around 40 words\",\n",
        "        \"Generate a realistic, thoughtful response to '{question_text}' while using the choices '{options}' naturally. Only provide the answer and nothing else\",\n",
        "        \"Respond as a user might: '{question_text}', with selected options '{options}'. Keep it engaging but realistic. Only provide the answer and nothing else\"\n",
        "    ],\n",
        "\n",
        "    \"TEXT\": [\n",
        "        \"Write a brief and realistic response to the question: {question_text}. Only provide the answer and nothing else\",\n",
        "        \"What might a user naturally say in response to: {question_text}? Keep it informal and user-focused. Only provide the answer and nothing else\",\n",
        "        \"Provide a thoughtful answer to '{question_text}', as a user might say in a real-world situation. Only provide the answer and nothing else\",\n",
        "        \"Answer the question '{question_text}' in a way that sounds natural and engaging, as if you were the user. Only provide the answer and nothing else\",\n",
        "        \"Generate a short, conversational response to the question: '{question_text}'. Only provide the answer and nothing else\"\n",
        "    ],\n",
        "\n",
        "    \"DATE\": [\n",
        "        \"Provide a realistic date for the question: '{question_text}'. Keep it plausible. Only provide the answer and nothing else\",\n",
        "        \"What date might a user reply with for '{question_text}'? Be concise and realistic. Only provide the answer and nothing else\",\n",
        "        \"Respond to '{question_text}' with a natural and plausible date in far future. Only provide the answer and nothing else\",\n",
        "        \"Imagine a user answering the question '{question_text}'. Provide a realistic date in near future they might give. Only provide the answer and nothing else\",\n",
        "        \"Generate a user-like response with a date in about 4 month to '{question_text}'. Only provide the answer and nothing else\"\n",
        "    ],\n",
        "\n",
        "    \"NUMBER\": [\n",
        "        \"Provide a realistic number in response to the question: '{question_text}'. Only provide the answer and nothing else containing a single number\",\n",
        "        \"What would a user answer to the question '{question_text}' with a number? Be realistic and concise. Only provide the answer and nothing else\",\n",
        "        \"Answer the question '{question_text}' as a user, using a plausible number. Only provide the answer and nothing else\",\n",
        "        \"Generate a thoughtful and natural response to '{question_text}', including a realistic number. Only provide the answer and nothing else\",\n",
        "        \"What might a user realistically say to '{question_text}' with a number? Only provide the answer and nothing else\"\n",
        "    ]\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "q_Kb1z4Pdawy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "def generate_response_gemini(prompt):\n",
        "    try:\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config={\n",
        "                \"temperature\": 0.7,\n",
        "                \"max_output_tokens\": 150\n",
        "            }\n",
        "        )\n",
        "        return response.text.strip() if response and response.text else None\n",
        "    except Exception as e:\n",
        "        print(f\"Fehler bei der Antwortgenerierung: {e}\")\n",
        "        return None\n",
        "\n",
        "# Reformulierte Fragen laden\n",
        "input_file = 'reformulated_combined_questions.json'\n",
        "with open(input_file, 'r') as f:\n",
        "    combined_questions = json.load(f)\n",
        "\n",
        "# Anzahl der Antworten pro Fragetyp\n",
        "target_counts = {\n",
        "    \"SINGLE_SELECT\": 700,\n",
        "    \"MULTI_SELECT\": 500,\n",
        "    \"TEXT\": 100,\n",
        "    \"DATE\": 100,\n",
        "    \"NUMBER\": 100\n",
        "}\n",
        "\n",
        "# Zähler für generierte Antworten pro Fragetyp\n",
        "generated_counts = {key: 0 for key in target_counts}\n",
        "\n",
        "# Simulierte Antworten erstellen\n",
        "generated_data = []\n",
        "\n",
        "for question in combined_questions:\n",
        "    if all(generated_counts[qt] >= target_counts[qt] for qt in target_counts):\n",
        "        break  # Abbrechen, wenn die Zielanzahl erreicht ist\n",
        "\n",
        "    question_id = question[\"id\"]\n",
        "    question_text = question[\"question\"]\n",
        "    question_type = question[\"type\"]\n",
        "    options = question.get(\"options\", [])\n",
        "\n",
        "    # Skip questions if their type has already reached the target count\n",
        "    if generated_counts[question_type] >= target_counts[question_type]:\n",
        "        continue\n",
        "\n",
        "    answers = []\n",
        "\n",
        "    if question_type == \"SINGLE_SELECT\":\n",
        "        for option in options:\n",
        "            if generated_counts[\"SINGLE_SELECT\"] >= target_counts[\"SINGLE_SELECT\"]:\n",
        "                break\n",
        "\n",
        "            if random.random() < 0.2:  # 20% Wahrscheinlichkeit für alternative Antwort\n",
        "                response = random.choice([\"I don't know\", \"I don't care\", \"\"])\n",
        "                answers.append({\n",
        "                    \"text\": response,\n",
        "                    \"label\": \"No Preference\",\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                })\n",
        "            else:\n",
        "                option_text = option[\"option\"]\n",
        "                prompt = random.choice(prompt_templates[\"SINGLE_SELECT\"]).format(\n",
        "                    question_text=question_text,\n",
        "                    option=option_text\n",
        "                )\n",
        "                response = generate_response_gemini(prompt)\n",
        "                time.sleep(5)  # Verzögerung\n",
        "                answers.append({\n",
        "                    \"text\": response if response else \"No Response\",\n",
        "                    \"label\": option_text,\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                })\n",
        "            generated_counts[\"SINGLE_SELECT\"] += 1\n",
        "\n",
        "    elif question_type == \"MULTI_SELECT\":\n",
        "        for _ in range(5):\n",
        "            if generated_counts[\"MULTI_SELECT\"] >= target_counts[\"MULTI_SELECT\"]:\n",
        "                break\n",
        "\n",
        "            if random.random() < 0.2:\n",
        "                response = random.choice([\"I don't know\", \"I don't care\", \"\"])\n",
        "                answers.append({\n",
        "                    \"text\": response,\n",
        "                    \"label\": \"No Preference\",\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                })\n",
        "            else:\n",
        "                selected_options = random.sample(options, k=random.randint(1, len(options)))\n",
        "                selected_texts = [opt[\"option\"] for opt in selected_options]\n",
        "                prompt = random.choice(prompt_templates[\"MULTI_SELECT\"]).format(\n",
        "                    question_text=question_text,\n",
        "                    options=\", \".join(selected_texts)\n",
        "                )\n",
        "                response = generate_response_gemini(prompt)\n",
        "                time.sleep(5)\n",
        "                answers.append({\n",
        "                    \"text\": response if response else \"No Response\",\n",
        "                    \"label\": selected_texts,\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                })\n",
        "            generated_counts[\"MULTI_SELECT\"] += 1\n",
        "\n",
        "    elif question_type in [\"TEXT\", \"DATE\", \"NUMBER\"]:\n",
        "        for _ in range(5):\n",
        "            if generated_counts[question_type] >= target_counts[question_type]:\n",
        "                break\n",
        "\n",
        "            if random.random() < 0.2:\n",
        "                response = random.choice([\"I don't know\", \"I don't care\", \"\"])\n",
        "                answers.append({\n",
        "                    \"text\": response,\n",
        "                    \"label\": \"No Preference\",\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                })\n",
        "            else:\n",
        "                prompt = random.choice(prompt_templates[question_type]).format(\n",
        "                    question_text=question_text\n",
        "                )\n",
        "                response = generate_response_gemini(prompt)\n",
        "                time.sleep(5)\n",
        "                answers.append({\n",
        "                    \"text\": response if response else \"No Response\",\n",
        "                    \"label\": question_type.capitalize(),\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                })\n",
        "            generated_counts[question_type] += 1\n",
        "\n",
        "    # Antwort zur Liste hinzufügen\n",
        "    generated_data.append({\n",
        "        \"question_id\": question_id,\n",
        "        \"question\": question_text,\n",
        "        \"type\": question_type,\n",
        "        \"answers\": answers\n",
        "    })\n",
        "\n",
        "# Ergebnisse in einer JSON-Datei speichern\n",
        "output_file = 'generated_responses.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(generated_data, f, indent=4)\n",
        "\n",
        "print(f\"Simulierte Antworten wurden in '{output_file}' gespeichert.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1A2TtdOEKK7w",
        "outputId": "bb73576b-9c3e-46b9-f1c1-71e51094b661"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulierte Antworten wurden in 'generated_responses_natural_language.json' gespeichert.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c20411ce-9b14-4449-be38-a3e5e5f2ba78\", \"generated_responses_natural_language.json\", 29752)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Datei herunterladen\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ik_XC7w6QtSN",
        "outputId": "842bf93a-7573-41e8-bbd3-f2497c82889b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0bf45dd3-023f-4f41-ae3d-c20e6330c262\", \"generated_responses_natural_language.json\", 51213)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# JSON-Datei laden\n",
        "with open(output_file, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Daten in ein DataFrame umwandeln\n",
        "rows = []\n",
        "for entry in data:\n",
        "    question_id = entry[\"question_id\"]\n",
        "    question = entry[\"question\"]\n",
        "    question_type = entry[\"type\"]\n",
        "    for answer in entry[\"answers\"]:\n",
        "        rows.append({\n",
        "            \"question_id\": question_id,\n",
        "            \"question\": question,\n",
        "            \"type\": question_type,\n",
        "            \"answer_text\": answer[\"text\"],\n",
        "            \"answer_label\": answer[\"label\"]\n",
        "        })\n",
        "\n",
        "# DataFrame erstellen\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# DataFrame anzeigen\n",
        "print(df.head())\n",
        "\n",
        "# DataFrame speichern (optional)\n",
        "output_file = 'questions_and_answers.csv'\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"DataFrame wurde in '{output_file}' gespeichert.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUYEus4LaWeu",
        "outputId": "742c3cde-6053-4f80-a75f-23844697e197"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            question_id                     question  \\\n",
            "0  aa2d8cdd-0758-4035-b0b6-ca18e2f380d8    May we process your data?   \n",
            "1  aa2d8cdd-0758-4035-b0b6-ca18e2f380d8    May we process your data?   \n",
            "2  12e1ed1d-edaa-4e93-8645-de3850e998f9  What's your customer group?   \n",
            "3  12e1ed1d-edaa-4e93-8645-de3850e998f9  What's your customer group?   \n",
            "4  12e1ed1d-edaa-4e93-8645-de3850e998f9  What's your customer group?   \n",
            "\n",
            "            type                                        answer_text  \\\n",
            "0  SINGLE_SELECT                                       I don't care   \n",
            "1  SINGLE_SELECT   No, I do not consent to my data being processed.   \n",
            "2  SINGLE_SELECT                          End users and businesses.   \n",
            "3  SINGLE_SELECT  We primarily serve wholesalers and distributor...   \n",
            "4  SINGLE_SELECT             Consultants, planners, and architects.   \n",
            "\n",
            "                     answer_label  \n",
            "0                   No Preference  \n",
            "1                              No  \n",
            "2                        End User  \n",
            "3         Wholesaler, Distributor  \n",
            "4  Consultant, Planner, Architect  \n",
            "DataFrame wurde in 'questions_and_answers.csv' gespeichert.\n"
          ]
        }
      ]
    }
  ]
}